{
  "best_global_step": 702,
  "best_metric": 0.007272462360560894,
  "best_model_checkpoint": "./minimodelos/modelo_intencion_entrenado\\checkpoint-702",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 702,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.042735042735042736,
      "grad_norm": 2.783046245574951,
      "learning_rate": 4.928774928774929e-05,
      "loss": 1.9386,
      "step": 10
    },
    {
      "epoch": 0.08547008547008547,
      "grad_norm": 2.7389333248138428,
      "learning_rate": 4.8575498575498576e-05,
      "loss": 1.9224,
      "step": 20
    },
    {
      "epoch": 0.1282051282051282,
      "grad_norm": 4.234820365905762,
      "learning_rate": 4.786324786324787e-05,
      "loss": 1.7994,
      "step": 30
    },
    {
      "epoch": 0.17094017094017094,
      "grad_norm": 8.12381649017334,
      "learning_rate": 4.7150997150997157e-05,
      "loss": 1.682,
      "step": 40
    },
    {
      "epoch": 0.21367521367521367,
      "grad_norm": 7.16358757019043,
      "learning_rate": 4.643874643874644e-05,
      "loss": 1.5612,
      "step": 50
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 7.680598258972168,
      "learning_rate": 4.572649572649573e-05,
      "loss": 1.2883,
      "step": 60
    },
    {
      "epoch": 0.29914529914529914,
      "grad_norm": 8.687519073486328,
      "learning_rate": 4.501424501424502e-05,
      "loss": 1.0238,
      "step": 70
    },
    {
      "epoch": 0.3418803418803419,
      "grad_norm": 6.591143608093262,
      "learning_rate": 4.4301994301994304e-05,
      "loss": 0.814,
      "step": 80
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 3.635342836380005,
      "learning_rate": 4.358974358974359e-05,
      "loss": 0.6041,
      "step": 90
    },
    {
      "epoch": 0.42735042735042733,
      "grad_norm": 5.427299976348877,
      "learning_rate": 4.287749287749288e-05,
      "loss": 0.6389,
      "step": 100
    },
    {
      "epoch": 0.4700854700854701,
      "grad_norm": 2.0769765377044678,
      "learning_rate": 4.216524216524217e-05,
      "loss": 0.3838,
      "step": 110
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 2.760053873062134,
      "learning_rate": 4.145299145299146e-05,
      "loss": 0.3789,
      "step": 120
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 9.755548477172852,
      "learning_rate": 4.074074074074074e-05,
      "loss": 0.2388,
      "step": 130
    },
    {
      "epoch": 0.5982905982905983,
      "grad_norm": 12.758421897888184,
      "learning_rate": 4.002849002849003e-05,
      "loss": 0.2106,
      "step": 140
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 1.6292256116867065,
      "learning_rate": 3.931623931623932e-05,
      "loss": 0.0781,
      "step": 150
    },
    {
      "epoch": 0.6837606837606838,
      "grad_norm": 0.6129478812217712,
      "learning_rate": 3.8603988603988605e-05,
      "loss": 0.1053,
      "step": 160
    },
    {
      "epoch": 0.7264957264957265,
      "grad_norm": 1.237201452255249,
      "learning_rate": 3.789173789173789e-05,
      "loss": 0.0428,
      "step": 170
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.6154915690422058,
      "learning_rate": 3.717948717948718e-05,
      "loss": 0.0947,
      "step": 180
    },
    {
      "epoch": 0.811965811965812,
      "grad_norm": 0.18238866329193115,
      "learning_rate": 3.646723646723647e-05,
      "loss": 0.0455,
      "step": 190
    },
    {
      "epoch": 0.8547008547008547,
      "grad_norm": 0.3167467713356018,
      "learning_rate": 3.575498575498576e-05,
      "loss": 0.1904,
      "step": 200
    },
    {
      "epoch": 0.8974358974358975,
      "grad_norm": 0.15051446855068207,
      "learning_rate": 3.504273504273504e-05,
      "loss": 0.0225,
      "step": 210
    },
    {
      "epoch": 0.9401709401709402,
      "grad_norm": 0.18243780732154846,
      "learning_rate": 3.433048433048433e-05,
      "loss": 0.0826,
      "step": 220
    },
    {
      "epoch": 0.9829059829059829,
      "grad_norm": 0.11327554285526276,
      "learning_rate": 3.361823361823362e-05,
      "loss": 0.0126,
      "step": 230
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.02939743362367153,
      "eval_runtime": 1.4003,
      "eval_samples_per_second": 1332.572,
      "eval_steps_per_second": 167.107,
      "step": 234
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 0.09468591213226318,
      "learning_rate": 3.290598290598291e-05,
      "loss": 0.0366,
      "step": 240
    },
    {
      "epoch": 1.0683760683760684,
      "grad_norm": 0.11384343355894089,
      "learning_rate": 3.2193732193732194e-05,
      "loss": 0.1012,
      "step": 250
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.0912991315126419,
      "learning_rate": 3.148148148148148e-05,
      "loss": 0.0104,
      "step": 260
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.07858425378799438,
      "learning_rate": 3.0769230769230774e-05,
      "loss": 0.0377,
      "step": 270
    },
    {
      "epoch": 1.1965811965811965,
      "grad_norm": 4.446185111999512,
      "learning_rate": 3.005698005698006e-05,
      "loss": 0.0507,
      "step": 280
    },
    {
      "epoch": 1.2393162393162394,
      "grad_norm": 5.993673801422119,
      "learning_rate": 2.9344729344729345e-05,
      "loss": 0.0927,
      "step": 290
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.06685974448919296,
      "learning_rate": 2.863247863247863e-05,
      "loss": 0.0065,
      "step": 300
    },
    {
      "epoch": 1.3247863247863247,
      "grad_norm": 0.06027722731232643,
      "learning_rate": 2.7920227920227922e-05,
      "loss": 0.005,
      "step": 310
    },
    {
      "epoch": 1.3675213675213675,
      "grad_norm": 0.05201854184269905,
      "learning_rate": 2.720797720797721e-05,
      "loss": 0.0053,
      "step": 320
    },
    {
      "epoch": 1.4102564102564101,
      "grad_norm": 0.0508318766951561,
      "learning_rate": 2.64957264957265e-05,
      "loss": 0.0054,
      "step": 330
    },
    {
      "epoch": 1.452991452991453,
      "grad_norm": 0.046783603727817535,
      "learning_rate": 2.5783475783475786e-05,
      "loss": 0.0048,
      "step": 340
    },
    {
      "epoch": 1.4957264957264957,
      "grad_norm": 0.06950950622558594,
      "learning_rate": 2.5071225071225073e-05,
      "loss": 0.0045,
      "step": 350
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.057617899030447006,
      "learning_rate": 2.435897435897436e-05,
      "loss": 0.004,
      "step": 360
    },
    {
      "epoch": 1.5811965811965814,
      "grad_norm": 0.037340302020311356,
      "learning_rate": 2.364672364672365e-05,
      "loss": 0.1345,
      "step": 370
    },
    {
      "epoch": 1.623931623931624,
      "grad_norm": 0.05945510417222977,
      "learning_rate": 2.2934472934472936e-05,
      "loss": 0.0852,
      "step": 380
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 11.406164169311523,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.0736,
      "step": 390
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 10.520172119140625,
      "learning_rate": 2.150997150997151e-05,
      "loss": 0.0093,
      "step": 400
    },
    {
      "epoch": 1.7521367521367521,
      "grad_norm": 0.046560198068618774,
      "learning_rate": 2.07977207977208e-05,
      "loss": 0.0292,
      "step": 410
    },
    {
      "epoch": 1.7948717948717947,
      "grad_norm": 0.044830407947301865,
      "learning_rate": 2.0085470085470087e-05,
      "loss": 0.0038,
      "step": 420
    },
    {
      "epoch": 1.8376068376068377,
      "grad_norm": 9.282865524291992,
      "learning_rate": 1.9373219373219374e-05,
      "loss": 0.0554,
      "step": 430
    },
    {
      "epoch": 1.8803418803418803,
      "grad_norm": 0.03847863897681236,
      "learning_rate": 1.866096866096866e-05,
      "loss": 0.0058,
      "step": 440
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.03231627494096756,
      "learning_rate": 1.794871794871795e-05,
      "loss": 0.0032,
      "step": 450
    },
    {
      "epoch": 1.965811965811966,
      "grad_norm": 0.032511208206415176,
      "learning_rate": 1.7236467236467238e-05,
      "loss": 0.0028,
      "step": 460
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0141981216147542,
      "eval_runtime": 1.3944,
      "eval_samples_per_second": 1338.202,
      "eval_steps_per_second": 167.813,
      "step": 468
    },
    {
      "epoch": 2.0085470085470085,
      "grad_norm": 0.04663510248064995,
      "learning_rate": 1.6524216524216525e-05,
      "loss": 0.0028,
      "step": 470
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 0.035067252814769745,
      "learning_rate": 1.581196581196581e-05,
      "loss": 0.0419,
      "step": 480
    },
    {
      "epoch": 2.094017094017094,
      "grad_norm": 0.03986796364188194,
      "learning_rate": 1.50997150997151e-05,
      "loss": 0.0031,
      "step": 490
    },
    {
      "epoch": 2.1367521367521367,
      "grad_norm": 0.04528825730085373,
      "learning_rate": 1.4387464387464389e-05,
      "loss": 0.003,
      "step": 500
    },
    {
      "epoch": 2.1794871794871793,
      "grad_norm": 0.03086816519498825,
      "learning_rate": 1.3675213675213677e-05,
      "loss": 0.0032,
      "step": 510
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.030374813824892044,
      "learning_rate": 1.2962962962962962e-05,
      "loss": 0.0027,
      "step": 520
    },
    {
      "epoch": 2.264957264957265,
      "grad_norm": 0.04197029396891594,
      "learning_rate": 1.2250712250712251e-05,
      "loss": 0.0031,
      "step": 530
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.031368158757686615,
      "learning_rate": 1.153846153846154e-05,
      "loss": 0.0026,
      "step": 540
    },
    {
      "epoch": 2.3504273504273505,
      "grad_norm": 0.051736049354076385,
      "learning_rate": 1.0826210826210826e-05,
      "loss": 0.0027,
      "step": 550
    },
    {
      "epoch": 2.393162393162393,
      "grad_norm": 0.02897423319518566,
      "learning_rate": 1.0113960113960115e-05,
      "loss": 0.0026,
      "step": 560
    },
    {
      "epoch": 2.435897435897436,
      "grad_norm": 0.018343904986977577,
      "learning_rate": 9.401709401709402e-06,
      "loss": 0.0988,
      "step": 570
    },
    {
      "epoch": 2.4786324786324787,
      "grad_norm": 0.03770790621638298,
      "learning_rate": 8.68945868945869e-06,
      "loss": 0.0023,
      "step": 580
    },
    {
      "epoch": 2.5213675213675213,
      "grad_norm": 0.02568981796503067,
      "learning_rate": 7.977207977207977e-06,
      "loss": 0.0023,
      "step": 590
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 0.03109820932149887,
      "learning_rate": 7.264957264957266e-06,
      "loss": 0.0023,
      "step": 600
    },
    {
      "epoch": 2.606837606837607,
      "grad_norm": 0.023852471262216568,
      "learning_rate": 6.5527065527065525e-06,
      "loss": 0.0817,
      "step": 610
    },
    {
      "epoch": 2.6495726495726495,
      "grad_norm": 0.03716658428311348,
      "learning_rate": 5.84045584045584e-06,
      "loss": 0.0024,
      "step": 620
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 0.15664297342300415,
      "learning_rate": 5.128205128205128e-06,
      "loss": 0.0152,
      "step": 630
    },
    {
      "epoch": 2.735042735042735,
      "grad_norm": 0.028066717088222504,
      "learning_rate": 4.415954415954416e-06,
      "loss": 0.0777,
      "step": 640
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.022504540160298347,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 0.0025,
      "step": 650
    },
    {
      "epoch": 2.8205128205128203,
      "grad_norm": 0.054854799062013626,
      "learning_rate": 2.991452991452992e-06,
      "loss": 0.0023,
      "step": 660
    },
    {
      "epoch": 2.8632478632478633,
      "grad_norm": 0.0450831800699234,
      "learning_rate": 2.2792022792022796e-06,
      "loss": 0.0024,
      "step": 670
    },
    {
      "epoch": 2.905982905982906,
      "grad_norm": 0.02454391121864319,
      "learning_rate": 1.566951566951567e-06,
      "loss": 0.0019,
      "step": 680
    },
    {
      "epoch": 2.948717948717949,
      "grad_norm": 0.04397609829902649,
      "learning_rate": 8.547008547008548e-07,
      "loss": 0.0028,
      "step": 690
    },
    {
      "epoch": 2.9914529914529915,
      "grad_norm": 0.026471855118870735,
      "learning_rate": 1.4245014245014247e-07,
      "loss": 0.0024,
      "step": 700
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.007272462360560894,
      "eval_runtime": 1.3848,
      "eval_samples_per_second": 1347.503,
      "eval_steps_per_second": 168.979,
      "step": 702
    }
  ],
  "logging_steps": 10,
  "max_steps": 702,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 46317008975832.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

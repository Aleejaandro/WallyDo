{
  "best_global_step": 690,
  "best_metric": 0.00802953913807869,
  "best_model_checkpoint": "./minimodelos/modelo_intencion_entrenado\\checkpoint-690",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 690,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.043478260869565216,
      "grad_norm": 2.8338494300842285,
      "learning_rate": 4.9275362318840584e-05,
      "loss": 1.946,
      "step": 10
    },
    {
      "epoch": 0.08695652173913043,
      "grad_norm": 3.5665345191955566,
      "learning_rate": 4.855072463768116e-05,
      "loss": 1.871,
      "step": 20
    },
    {
      "epoch": 0.13043478260869565,
      "grad_norm": 3.872218370437622,
      "learning_rate": 4.782608695652174e-05,
      "loss": 1.7449,
      "step": 30
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 6.982110023498535,
      "learning_rate": 4.710144927536232e-05,
      "loss": 1.4779,
      "step": 40
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 7.617025852203369,
      "learning_rate": 4.63768115942029e-05,
      "loss": 1.3052,
      "step": 50
    },
    {
      "epoch": 0.2608695652173913,
      "grad_norm": 10.270139694213867,
      "learning_rate": 4.565217391304348e-05,
      "loss": 1.23,
      "step": 60
    },
    {
      "epoch": 0.30434782608695654,
      "grad_norm": 7.077963352203369,
      "learning_rate": 4.492753623188406e-05,
      "loss": 0.9434,
      "step": 70
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 4.566025733947754,
      "learning_rate": 4.4202898550724645e-05,
      "loss": 0.6626,
      "step": 80
    },
    {
      "epoch": 0.391304347826087,
      "grad_norm": 14.028305053710938,
      "learning_rate": 4.347826086956522e-05,
      "loss": 0.7253,
      "step": 90
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 2.128082275390625,
      "learning_rate": 4.27536231884058e-05,
      "loss": 0.4503,
      "step": 100
    },
    {
      "epoch": 0.4782608695652174,
      "grad_norm": 3.943645477294922,
      "learning_rate": 4.202898550724638e-05,
      "loss": 0.429,
      "step": 110
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 2.9630424976348877,
      "learning_rate": 4.130434782608696e-05,
      "loss": 0.2116,
      "step": 120
    },
    {
      "epoch": 0.5652173913043478,
      "grad_norm": 10.022486686706543,
      "learning_rate": 4.057971014492754e-05,
      "loss": 0.1307,
      "step": 130
    },
    {
      "epoch": 0.6086956521739131,
      "grad_norm": 0.4920837879180908,
      "learning_rate": 3.985507246376812e-05,
      "loss": 0.0843,
      "step": 140
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 18.92934226989746,
      "learning_rate": 3.91304347826087e-05,
      "loss": 0.1362,
      "step": 150
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 0.2989102005958557,
      "learning_rate": 3.8405797101449274e-05,
      "loss": 0.0574,
      "step": 160
    },
    {
      "epoch": 0.7391304347826086,
      "grad_norm": 0.22292082011699677,
      "learning_rate": 3.7681159420289856e-05,
      "loss": 0.2034,
      "step": 170
    },
    {
      "epoch": 0.782608695652174,
      "grad_norm": 0.2517634630203247,
      "learning_rate": 3.695652173913043e-05,
      "loss": 0.0863,
      "step": 180
    },
    {
      "epoch": 0.8260869565217391,
      "grad_norm": 0.2442069798707962,
      "learning_rate": 3.6231884057971014e-05,
      "loss": 0.0186,
      "step": 190
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.14227436482906342,
      "learning_rate": 3.5507246376811596e-05,
      "loss": 0.013,
      "step": 200
    },
    {
      "epoch": 0.9130434782608695,
      "grad_norm": 0.14375334978103638,
      "learning_rate": 3.478260869565218e-05,
      "loss": 0.0835,
      "step": 210
    },
    {
      "epoch": 0.9565217391304348,
      "grad_norm": 4.790514945983887,
      "learning_rate": 3.405797101449276e-05,
      "loss": 0.0132,
      "step": 220
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1412566900253296,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0837,
      "step": 230
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.047727055847644806,
      "eval_runtime": 1.4957,
      "eval_samples_per_second": 1227.499,
      "eval_steps_per_second": 153.772,
      "step": 230
    },
    {
      "epoch": 1.0434782608695652,
      "grad_norm": 0.061578113585710526,
      "learning_rate": 3.260869565217392e-05,
      "loss": 0.1995,
      "step": 240
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.3086071312427521,
      "learning_rate": 3.188405797101449e-05,
      "loss": 0.0438,
      "step": 250
    },
    {
      "epoch": 1.1304347826086956,
      "grad_norm": 0.10942116379737854,
      "learning_rate": 3.1159420289855074e-05,
      "loss": 0.0441,
      "step": 260
    },
    {
      "epoch": 1.1739130434782608,
      "grad_norm": 0.056586191058158875,
      "learning_rate": 3.0434782608695656e-05,
      "loss": 0.0082,
      "step": 270
    },
    {
      "epoch": 1.2173913043478262,
      "grad_norm": 0.0630134716629982,
      "learning_rate": 2.971014492753623e-05,
      "loss": 0.0317,
      "step": 280
    },
    {
      "epoch": 1.2608695652173914,
      "grad_norm": 0.06180616095662117,
      "learning_rate": 2.8985507246376814e-05,
      "loss": 0.0063,
      "step": 290
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.061412032693624496,
      "learning_rate": 2.826086956521739e-05,
      "loss": 0.0059,
      "step": 300
    },
    {
      "epoch": 1.3478260869565217,
      "grad_norm": 0.267342209815979,
      "learning_rate": 2.753623188405797e-05,
      "loss": 0.0069,
      "step": 310
    },
    {
      "epoch": 1.391304347826087,
      "grad_norm": 0.055706534534692764,
      "learning_rate": 2.6811594202898553e-05,
      "loss": 0.007,
      "step": 320
    },
    {
      "epoch": 1.434782608695652,
      "grad_norm": 0.05766434594988823,
      "learning_rate": 2.608695652173913e-05,
      "loss": 0.0099,
      "step": 330
    },
    {
      "epoch": 1.4782608695652173,
      "grad_norm": 0.05660318210721016,
      "learning_rate": 2.5362318840579714e-05,
      "loss": 0.0051,
      "step": 340
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 0.0491766631603241,
      "learning_rate": 2.4637681159420292e-05,
      "loss": 0.0923,
      "step": 350
    },
    {
      "epoch": 1.5652173913043477,
      "grad_norm": 0.051067791879177094,
      "learning_rate": 2.391304347826087e-05,
      "loss": 0.0173,
      "step": 360
    },
    {
      "epoch": 1.608695652173913,
      "grad_norm": 0.33466604351997375,
      "learning_rate": 2.318840579710145e-05,
      "loss": 0.0923,
      "step": 370
    },
    {
      "epoch": 1.6521739130434783,
      "grad_norm": 0.0483359731733799,
      "learning_rate": 2.246376811594203e-05,
      "loss": 0.0038,
      "step": 380
    },
    {
      "epoch": 1.6956521739130435,
      "grad_norm": 0.03529029339551926,
      "learning_rate": 2.173913043478261e-05,
      "loss": 0.0194,
      "step": 390
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.06568700075149536,
      "learning_rate": 2.101449275362319e-05,
      "loss": 0.0037,
      "step": 400
    },
    {
      "epoch": 1.7826086956521738,
      "grad_norm": 0.049673888832330704,
      "learning_rate": 2.028985507246377e-05,
      "loss": 0.0735,
      "step": 410
    },
    {
      "epoch": 1.8260869565217392,
      "grad_norm": 0.03216129541397095,
      "learning_rate": 1.956521739130435e-05,
      "loss": 0.0032,
      "step": 420
    },
    {
      "epoch": 1.8695652173913042,
      "grad_norm": 0.034962382167577744,
      "learning_rate": 1.8840579710144928e-05,
      "loss": 0.0998,
      "step": 430
    },
    {
      "epoch": 1.9130434782608696,
      "grad_norm": 0.04217984154820442,
      "learning_rate": 1.8115942028985507e-05,
      "loss": 0.1581,
      "step": 440
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 0.039045196026563644,
      "learning_rate": 1.739130434782609e-05,
      "loss": 0.0062,
      "step": 450
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.040813177824020386,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0033,
      "step": 460
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.01746518537402153,
      "eval_runtime": 1.4468,
      "eval_samples_per_second": 1268.988,
      "eval_steps_per_second": 158.969,
      "step": 460
    },
    {
      "epoch": 2.0434782608695654,
      "grad_norm": 1.375422477722168,
      "learning_rate": 1.5942028985507246e-05,
      "loss": 0.0038,
      "step": 470
    },
    {
      "epoch": 2.0869565217391304,
      "grad_norm": 0.05306519195437431,
      "learning_rate": 1.5217391304347828e-05,
      "loss": 0.0049,
      "step": 480
    },
    {
      "epoch": 2.130434782608696,
      "grad_norm": 0.025456396862864494,
      "learning_rate": 1.4492753623188407e-05,
      "loss": 0.0028,
      "step": 490
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.03157547116279602,
      "learning_rate": 1.3768115942028985e-05,
      "loss": 0.0027,
      "step": 500
    },
    {
      "epoch": 2.217391304347826,
      "grad_norm": 0.032843876630067825,
      "learning_rate": 1.3043478260869566e-05,
      "loss": 0.0905,
      "step": 510
    },
    {
      "epoch": 2.260869565217391,
      "grad_norm": 0.03924424573779106,
      "learning_rate": 1.2318840579710146e-05,
      "loss": 0.0029,
      "step": 520
    },
    {
      "epoch": 2.3043478260869565,
      "grad_norm": 0.04214683920145035,
      "learning_rate": 1.1594202898550725e-05,
      "loss": 0.054,
      "step": 530
    },
    {
      "epoch": 2.3478260869565215,
      "grad_norm": 0.03778700530529022,
      "learning_rate": 1.0869565217391305e-05,
      "loss": 0.0026,
      "step": 540
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": 0.03772725164890289,
      "learning_rate": 1.0144927536231885e-05,
      "loss": 0.0026,
      "step": 550
    },
    {
      "epoch": 2.4347826086956523,
      "grad_norm": 0.03399169445037842,
      "learning_rate": 9.420289855072464e-06,
      "loss": 0.0025,
      "step": 560
    },
    {
      "epoch": 2.4782608695652173,
      "grad_norm": 0.040062323212623596,
      "learning_rate": 8.695652173913044e-06,
      "loss": 0.0026,
      "step": 570
    },
    {
      "epoch": 2.5217391304347827,
      "grad_norm": 0.024788957089185715,
      "learning_rate": 7.971014492753623e-06,
      "loss": 0.0025,
      "step": 580
    },
    {
      "epoch": 2.5652173913043477,
      "grad_norm": 0.024226808920502663,
      "learning_rate": 7.246376811594203e-06,
      "loss": 0.0024,
      "step": 590
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.026803160086274147,
      "learning_rate": 6.521739130434783e-06,
      "loss": 0.0022,
      "step": 600
    },
    {
      "epoch": 2.6521739130434785,
      "grad_norm": 0.027499636635184288,
      "learning_rate": 5.797101449275362e-06,
      "loss": 0.0025,
      "step": 610
    },
    {
      "epoch": 2.6956521739130435,
      "grad_norm": 0.020315859466791153,
      "learning_rate": 5.072463768115943e-06,
      "loss": 0.0022,
      "step": 620
    },
    {
      "epoch": 2.7391304347826084,
      "grad_norm": 0.02169863134622574,
      "learning_rate": 4.347826086956522e-06,
      "loss": 0.0716,
      "step": 630
    },
    {
      "epoch": 2.782608695652174,
      "grad_norm": 0.0706525444984436,
      "learning_rate": 3.6231884057971017e-06,
      "loss": 0.0107,
      "step": 640
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": 0.022710977122187614,
      "learning_rate": 2.898550724637681e-06,
      "loss": 0.0095,
      "step": 650
    },
    {
      "epoch": 2.869565217391304,
      "grad_norm": 0.03559866175055504,
      "learning_rate": 2.173913043478261e-06,
      "loss": 0.039,
      "step": 660
    },
    {
      "epoch": 2.9130434782608696,
      "grad_norm": 0.0541437566280365,
      "learning_rate": 1.4492753623188406e-06,
      "loss": 0.0024,
      "step": 670
    },
    {
      "epoch": 2.9565217391304346,
      "grad_norm": 0.028962429612874985,
      "learning_rate": 7.246376811594203e-07,
      "loss": 0.0436,
      "step": 680
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.029728103429079056,
      "learning_rate": 0.0,
      "loss": 0.0024,
      "step": 690
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.00802953913807869,
      "eval_runtime": 1.4605,
      "eval_samples_per_second": 1257.073,
      "eval_steps_per_second": 157.477,
      "step": 690
    }
  ],
  "logging_steps": 10,
  "max_steps": 690,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 45574918398288.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
